{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExtractTable Usage -2.1.0",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "BnYb9aztB48u",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExtractTable/ExtractTable-py/blob/master/example-code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "935SwBV4Z-CH",
        "colab_type": "text"
      },
      "source": [
        "# 1. Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhVhMrQ0ZdQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U ExtractTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfsHIegraT2l",
        "colab_type": "text"
      },
      "source": [
        "# 2. Import and check version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIaghfeZnQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ExtractTable import ExtractTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLLCa6qQaaZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(ExtractTable.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYERq5s9aiNy",
        "colab_type": "text"
      },
      "source": [
        "# 3. Create Session & Validate API Key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwtpzTJxZHRi",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 **Create Session** with your API Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJL_ZyYzZsFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "api_key = YOUR_APIKEY_HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfw5GTNvZGv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "et_sess = ExtractTable(api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5fQB7dGxLKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# et_sess.__dict__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On4_X8v3Zk3v",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 **Validate** the Key and check the plan usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7EPvvvMZ0Ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usage = et_sess.check_usage()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sovuclERjRqy",
        "colab_type": "text"
      },
      "source": [
        "*If there is no error encountered in the above cell, it means we have a valid API key. Now, lets get started by checking the usage and trigger the file for processing*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJdjlTPKxcXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# et_sess.server_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT97IP8MZ9WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc872e57-c5cb-4db0-a034-56f03f275d4b"
      },
      "source": [
        "print(usage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'credits': 100, 'queued': 0, 'used': 49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XqbBoB-i3pi",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Check Usage Details\n",
        "\n",
        "**credits**: Total number credits attached to the API Key\n",
        "\n",
        "**queued** : Number of triggered jobs that are still processing in the queue\n",
        "\n",
        "**used**   : Number of credits already used "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARRJaIgFcYoe",
        "colab_type": "text"
      },
      "source": [
        "# 4. Trigger the extraction process\n",
        "\n",
        "> Note: We will use the session, `et_sess`, created earlier in step 3.1, to save the session data and retrieve when needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GpN9ho1chi6",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Accepted Input Types\n",
        "\n",
        "**Allowed input formats** are:\n",
        "- Image\n",
        "  - JPG/JPEG\n",
        "  - PNG\n",
        "- PDF\n",
        "  - Text PDF\n",
        "  - Scan PDF\n",
        "  - Image PDF\n",
        "\n",
        "\n",
        "**Input Location Options**\n",
        "- Location can be a file from the local drive\n",
        "- Accessible remote URL - *the file object will be locally downloaded and deleted once sent to the process*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_xzVgHmZ9sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_location = \"local_image_path_OR_remote_image_url_with_tables\"\n",
        "# image_location = r'samples/BlurryImage.jpg'\n",
        "image_location = \"https://raw.githubusercontent.com/ExtractTable/ExtractTable-py/master/samples/QualityImage.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUnBFxYiZ1Ka",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Process an <ins>IMAGE</ins> Input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9jzk6wJ5-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_data = et_sess.process_file(filepath=image_location, output_format=\"df\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoKuQBVQy3LN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "032898c5-0a6b-41b7-a9fc-4107defe056f"
      },
      "source": [
        "table_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[          0                           1  ...      5                   6\n",
              " 0  FLC Code                   Room Name  ...  W (m)  Ceiling Height (m)\n",
              " 1   RGOOTO1  Indigenous Support Officer  ...    7.3                 2.7\n",
              " 2   RGOOTO2         Instrum. Music Room  ...    7.3                 2.7\n",
              " 3   RGOTO1A                    Verandah  ...    1.7                 3.0\n",
              " 4   RGOTO1B              Eastern Stairs  ...    1.7                 N/A\n",
              " 5   RGOTO2B              Western Stairs  ...    1.0                 N/A\n",
              " \n",
              " [6 rows x 7 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uiDCtGpfTwF",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Process a <ins>PDF</ins> Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehxmaPgthoCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pdf_location = \"local_image_path_OR_remote_image_url_with_tables\"\n",
        "# pdf_location = r'samples/BlurryImage.jpg'\n",
        "pdf_location = \"https://raw.githubusercontent.com/ExtractTable/ExtractTable-py/master/samples/QualityImage.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdU1Au3LhiuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_data = et_sess.process_file(filepath=Location_of_PDF_with_Tables, pages=\"all\", output_format=\"df\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k98KTihPJwyO",
        "colab_type": "text"
      },
      "source": [
        "Below are the sample values ```pages``` accepts **string** type\n",
        "\n",
        "\n",
        "\n",
        "| pages  \t| Explanation                                     \t|\n",
        "|----------\t|-------------------------------------------------\t|\n",
        "| \"1\"      \t| [Default] considers only 1st page of the PDF    \t|\n",
        "| \"1,3,5\"  \t| considers only 1st, 3rd and 5th page of the PDF \t|\n",
        "| \"1, 3-5\" \t| considers 1st, 3rd, 4th and 5th page of the PDF \t|\n",
        "| \"all\"    \t| considers complete PDF                          \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-KPdSNQBeR-",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Table Output options\n",
        "\n",
        "> By default, the `process_file()` returns **only** the table data. Output depends on the `output_format` , explained below\n",
        "\n",
        "Explore the available options with `ExtractTable._OUTPUT_FORMATS`\n",
        "\n",
        "| output_format \t| Explanation                                \t|\n",
        "|---------------\t|--------------------------------------------\t|\n",
        "| \"df\"          \t| [Default] Array of Pandas dataframes        \t|\n",
        "| \"dataframe\"   \t| same as \"df\"; Array of Pandas dataframes    \t|\n",
        "| \"json\"        \t| JSON data with index orientation           \t|\n",
        "| \"dict\"        \t| Similar to JSON data but python dictionary \t|\n",
        "| \"csv\"         \t| Array of locally saved CSV file locations   \t|\n",
        "| \"xlsx\"         \t| To save multiple tables as sheets into a single excel\t|\n",
        "| \"excel\"         | same as \"xlsx\"; output is an array of excel location\t|\n",
        "\n",
        "\n",
        "Default output is an array of pandas dataframes, with which you can change to any other format like excel, html etc. Follow https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ1as9mkCOyu",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 Explore session objects\n",
        "\n",
        "> **Explore** all objects of the latest file processing with `et_sess.__dict__.\n",
        "keys()` - Depends on the plan type of your API Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDUaDyX8IGmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b89cd4d2-72a1-4196-ad6e-2a05cc6f0448"
      },
      "source": [
        "et_sess.__dict__.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['api_key', '_session', 'ServerResponse', 'JobStatus', 'Lines', 'Pages', 'Tables'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Z6RJa9DFlT",
        "colab_type": "text"
      },
      "source": [
        "Based on the API Key PLAN type, the et_sess contains below objects\n",
        "\n",
        "| Object          \t| Explanation                                                                            \t|\n",
        "|-----------------\t|----------------------------------------------------------------------------------------\t|\n",
        "| api_key         \t| Your API Key                                                                           \t|\n",
        "| _session        \t| Session data of the **latest** performed request/action                                          \t|\n",
        "| input_filename  \t| Name of the processed input file |\n",
        "| ServerResponse  \t| Complete ServerResponse, along with response code and headers                          \t|\n",
        "| server_response \t| complete server response content; equivalent to `ServerResponse.json()`                \t|\n",
        "| JobStatus       \t| Job Status of the triggered process                                                    \t|\n",
        "| Pages           \t| Number of pages in the input; also number of credits consumed on the triggered process \t|\n",
        "| Tables          \t| Tabular Data in JSON format with index orientation; ordered table wise                 \t|\n",
        "| Lines           \t| Text Data in JSON format, ordered page wise                                            \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MytCD36ja6KM",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 Save Table & Text to LOCAL\n",
        "\n",
        "```python\n",
        "et_sess.save_output(output_folder, output_format=\"csv\")\n",
        "```\n",
        "`output_format` param is relavant only for the table data, with options \"csv\" or \"xlsx\"\n",
        "\n",
        "\n",
        "> Note: As the `et_sess` contains the latest action performed, make sure this call is right after the `process_file()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CgU2PCJFQNr",
        "colab_type": "text"
      },
      "source": [
        "# 5. Explore the Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI-CLS9UF0iS",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Output Structure\n",
        "\n",
        "> **Understand the output**: The response of a triggered job is a JSON object in the below format. \n",
        "\n",
        "Note that the response depends on the plan type of the API Key.\n",
        "\n",
        "\n",
        "```javascript\n",
        "{\n",
        "    \"JobStatus\": <string>,                              # Status of the triggered Process  @ JOB-LEVEL\n",
        "    \"Pages\": <integer>,                                 # Number of pages processed in this request @ PAGE-LEVEL\n",
        "    \"Tables\": [<list of key-value objects of table>     # List of all tables found @ TABLE-LEVEL\n",
        "        {\n",
        "            \"Page\": <integer>,                              ## Page number in which this table is found\n",
        "            \"CharacterConfidence\": <float>,                 ## Accuracy of Characters recognized from the input-page\n",
        "            \"LayoutConfidence\": <float>,                    ## Accuracy of table layout's design decision\n",
        "            \"TableJson\": <dict>,                            ## Table Cell Text in key-value format with index orientation - {row#: {col#: <str>}}\n",
        "            \"TableCoordinates\": <dict>,                     ## Top-left & Bottom-right Cell Coordinates - {row#: {col#: <list(x1,y1,x2,y2)>}}\n",
        "            \"TableConfidence\": <dict>                       ## Cell level accuracy of detected characters - {row#: {col#: <float>}}\n",
        "        },\n",
        "    {...}                                               ## ... more \"Tables\" objects\n",
        "    ],\n",
        "    \"Lines\": [<list of key-value objects>               # Pagewise Line details @ PAGE-LEVEL\n",
        "        {\n",
        "            \"Page\": <integer>,                          # Page number in which the lines are found\n",
        "            \"CharacterConfidence\": <float>,             # Average Accuracy of all Characters recognized from the input-page\n",
        "            \"LinesArray\": [\n",
        "                <list of key-value objects of line>     # Ordered list of lines in this page @ LINE-LEVEL\n",
        "                {\n",
        "                    \"Line\": <str>,                          ## Detected text of the complete line\n",
        "                    \"WordsArray\": [\n",
        "                        <list of key-value objects>         ## Word level datails in this line @ WORD-LEVEL\n",
        "                        {\n",
        "                            \"Conf\": <float>,                    ### Accuracy of recognized characters of the word\n",
        "                            \"Word\": <str>,                      ### Detected text of the word\n",
        "                            \"Loc\": [x1, y1, x2, y2]             ### Top-left & Bottom-right coordinates, w.r.t the input-page width-height dimensions\n",
        "                        },\n",
        "                    {...}                                   ### More \"WordsArray\" objects\n",
        "                    ]\n",
        "                },\n",
        "            {...}                                       ## More \"LinesArray\" objects\n",
        "            ]\n",
        "        },\n",
        "    {...}                                               # More Pagewise \"Lines\" details\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPY9KziZF6jR",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Output Details\n",
        "\n",
        "Output objects are based on the API Key Plan type. Available plan types are \n",
        "\n",
        "**Purchased Plans**\n",
        "*   \"LITE\"   - **only table data** in the output\n",
        "*   \"FULL\"   - **table and text data** in the output\n",
        "*   \"EXTRA\"  - **table, text data along with cell & word coordintates and character detection accuracy**\n",
        "\n",
        "**Promotional Plans**: Any plan other than Purchased plans are promotional\n",
        "*   \"free_trial\", \"camelotpro\" - these are promotional API Keys, gives only table data equivalent to \"LITE\" plan type\n",
        "\n",
        "\n",
        "<br>\n",
        "Output objects detail below\n",
        "\n",
        "\n",
        "\n",
        "| Key Name \t| Parent \t| Type \t| Description \t| Availability \t|\n",
        "|-\t|-\t|-\t|-\t|-\t|\n",
        "| JobStatus \t| Job \t| String \t| Status of the triggered process \t| ALL Plans \t|\n",
        "| Pages \t| Job \t| Integer \t| Number of pages processed in the request \t| ALL Plans \t|\n",
        "| Tables \t| Job \t| Array \t| List of all tables found \t| ALL Plans \t|\n",
        "| Tables[0].Page \t| Table \t| Integer \t| Page number in which the table is found \t| ALL Plans \t|\n",
        "| Tables[0].CharacterConfidence \t| Table \t| Decimal \t| Accuracy of Characters recognized from the image \t| ALL Plans \t|\n",
        "| Tables[0].LayoutConfidence \t| Table \t| Decimal \t| Accuracy of table layout's design decision \t| ALL Plans \t|\n",
        "| Tables[0].TableJson \t| Table \t| Json/dict \t| Table Cell Text in key-value format with index orientation - {row#: {col#: }} \t| ALL Plans \t|\n",
        "| Tables[0].TableCoordinates \t| Table \t| Json/dict \t| Top-left & Bottom-right Cell Coordinates - {row#: {col#: }} \t| EXTRA Plan \t|\n",
        "| Tables[0].TableConfidence \t| Table \t| Json/dict \t| Cell level accuracy of detected characters - {row#: {col#: }} \t| EXTRA Plan \t|\n",
        "| Lines \t| Job \t| Array \t| List of page-wise lines text \t| FULL, EXTRA\t|\n",
        "| Lines[0].Page \t| Page \t| Integer \t| Page number in which the lines are found \t| Full Plan \t|\n",
        "| Lines[0].CharacterConfidence \t| Page \t| Decimal \t| Average Accuracy of all Characters recognized from the input-page \t| Full Plan \t|\n",
        "| Lines[0].LineArray \t| Page \t| Array \t| Ordered list of lines of the page \t|  \t|\n",
        "| Lines[0].LineArray[0].Line \t| Line \t| String \t| Detected text of the complete line \t| Full Plan \t|\n",
        "| Lines[0].LineArray[0].WordsArray \t| Line \t| Array \t| Word level datails in this line \t| EXTRA Plan \t|\n",
        "| Lines[0].LineArray[0].WordsArray[0].Conf \t| Word \t| Decimal \t| Accuracy of recognized characters of the word \t| EXTRA Plan \t|\n",
        "| Lines[0].LineArray[0].WordsArray[0].Word \t| Word \t| String \t| Detected text of the word \t| EXTRA Plan \t|\n",
        "| Lines[0].LineArray[0].WordsArray[0].Loc \t| Word \t| Array \t| Top-left & Bottom-right coordinates, w.r.t the input-page width-height dimensions \t| EXTRA Plan \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ysCj8_GSrd8",
        "colab_type": "text"
      },
      "source": [
        "# 6. Make Corrections\n",
        "\n",
        "> **Objective**: To ease corrections on the most common issues with the `MakeCorrections` module.\n",
        "\n",
        "**Details:** The service relies on OCR (Optical Character Recognition) for character detection and deep learning models to detect tabular structures on the input. There may be a chance for merged rows or columns or incorrect type detections on low-quality inputs with a complex table layout or tightly packed columns. With those in mind, we want to offer the built-in service at the client-side to give control and ease in making corrections on the output. \n",
        "\n",
        "\n",
        "The module, `MakeCorrections`, currently supports below functionalities\n",
        "\n",
        "| Functionality        \t| Explanation                                    \t|\n",
        "|----------------------\t|------------------------------------------------\t|\n",
        "| Split Merged Rows    \t| Works well on cell values with no spaces       \t|\n",
        "| Split Merged Columns \t| Works well on cell values with no spaces       \t|\n",
        "| Fix Decimal Format   \t| To fix thousand and decimal separators         \t|\n",
        "| Fix Date Format      \t| To handle and modify incorrect date separators \t|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpH284nxX2KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First things first lets import the module and prepare for corrections\n",
        "\n",
        "from ExtractTable.common import MakeCorrections\n",
        "\n",
        "corrections = MakeCorrections(et_resp=et_sess.server_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKRntUqYXIEQ",
        "colab_type": "text"
      },
      "source": [
        "## 6.1 Split Merged Rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MmSR0mLXS6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_table_dataframes = corrections.split_merged_rows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34YLZL3nXIU6",
        "colab_type": "text"
      },
      "source": [
        "## 6.2 Split Merged Columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzinneCWXVZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_table_dataframes = corrections.split_merged_columns()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XSBMo5rXIkC",
        "colab_type": "text"
      },
      "source": [
        "## 6.3 Fix Decimal Format\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK9nWOSfXXUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_table_dataframes = corrections.fix_decimal_format(decimal_separator=\".\", thousands_separator=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mok2QbmFXIz9",
        "colab_type": "text"
      },
      "source": [
        "## 6.4 Fix Date Format\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFQNzPxUSqga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrected_table_dataframes = corrections.fix_date_format(delimiter=\"/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5-CGT3oy7KG",
        "colab_type": "text"
      },
      "source": [
        "# 7. Helpful Code Snippets\n",
        "\n",
        "Extra code snippets that are useful to perform some actions on the output. Based on the frequently asked questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACcH7oUpMfFp",
        "colab_type": "text"
      },
      "source": [
        "## 7.1 Get text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CVAYfnK_sTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If your API Key supports \"Lines\"\n",
        "\n",
        "all_page_lines = []\n",
        "for each_page in et_sess.Lines:\n",
        "  for each_line in each_page['LinesArray']:\n",
        "    all_page_lines.append(each_line['Line'])\n",
        "  \n",
        "print(\"\\n\".join(all_page_lines))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0vnCiXM_FM",
        "colab_type": "text"
      },
      "source": [
        "## 7.2 All tables output to a single excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhOTglS-NIXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "table_data = et_sess.process_file(filepath=Location_of_PDF_with_Tables, output_format=\"df\", pages=\"all\")\n",
        " \n",
        "import pandas as pd\n",
        "accumulate_all_dfs = pd.DataFrame()\n",
        "\n",
        "for each_df in table_data:\n",
        "    accumulate_all_dfs = accumulate_all_dfs.append(each_df, ignore_index=True)\n",
        "    # print(each_df.shape, accumulate_all_dfs.shape)\n",
        "\n",
        "print(\"Shape of all tables accumulated together is\", accumulate_all_dfs.shape)\n",
        "\n",
        "\n",
        "output_excel_location = <location_for_the_excel_output.xlsx>\n",
        "# Save the accumulated output to a single excel file\n",
        "accumulate_all_dfs.to_excel(output_excel_location, index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba8vIKuXdAPT",
        "colab_type": "text"
      },
      "source": [
        "# 8. Support & Contact\n",
        "\n",
        "Please do not hesitate to approach our developer team at pydevs@extracttable.com for any assitance needed or to report a bug"
      ]
    }
  ]
}